{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUC Minas EAD - Trabalho de conclusão de curso\n",
    "\n",
    "Trabalho de conclusão de curso de Guilherme Fernando Angélico para o título de especialista em Inteligência Artificial e Machine Learning. 28/02/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print('Versão da linguagem python utilizada para a execução desse notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detectando transações fraudulentas de cartão de crédito com Inteligência Artificial - Uma abordagem não supervisionada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['Análise automatica de transações fraldulentas de cartão de crédito'](./images/analise-manual-de-risco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do problema\n",
    "\n",
    "Os sistemas comerciais sempre estão em constante evolução, e transacionar uma compra em um e-commerce é uma operação cada vez mais comum; E na mesma velocidade em que as transações ocorrem sempre há uma possibilidade de que essa transação seja fraudulenta, ou seja, não é o dententor do cartão efetuando a compra - uma pessoa maliciosa pode ter capturado esses dados e se passar por essa pessoa.\n",
    "\n",
    "Nesse projeto, vamos criar um sistema capaz de analisar as transações financeiras e criar um modelo capaz de prever uma classe para cada transação indicando se ela é uma Transação  **Válida** ou um **Fraude**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import rcParams\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score ,precision_score, recall_score, accuracy_score, precision_recall_curve, classification_report\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Análise de fraudes em transações com cartões de crédito\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Para modelar nosso sistema de análise de transações fraudulentas vamos utilizar um dataset público disponível no Kaggle:\n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "O dataset possui um total de 31 colunas. Sendo 28 colunas com valores numérico/decimal, obtidos através do processo de PCA - afim de proteger as identidades e recursos confidencias, e outras 3 colunas, sendo: Número de segundos entre a primeira transação do dataset e a atual, O valor da transação e a Classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "LABELS = [\"Normal\", \"Fraude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/creditcard.zip', sep=',', compression='zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise do dataset\n",
    "\n",
    "Vamos analisar o dataset e identicar as caracteristicas das transações desse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_class = pd.value_counts(df['Class'], sort = True)\n",
    "plt.title(\"Distribuição\")\n",
    "ax = sns.barplot(x=qtd_class.keys(), y=qtd_class.values)\n",
    "\n",
    "for p in ax.patches:\n",
    "    percent = '{:.1f}%'.format(100 * p.get_height()/len(df))\n",
    "    x = p.get_x() + p.get_width() / 2 - 0.05\n",
    "    y = p.get_y() + p.get_height()\n",
    "    ax.annotate(percent, (x, y), size=12)\n",
    "\n",
    "ax.set_xticks(range(len(LABELS)), LABELS)\n",
    "ax.set_xlabel(\"Classe\")\n",
    "ax.set_ylabel(\"Quantidade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma coluna de data/tempo para poder colocar nososs registros dentro de uma time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = dt.datetime(2013, 9, 1, 8, 0, 0)\n",
    "data_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Data'] = df['Time'].apply(lambda x: data_base + dt.timedelta(seconds=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[df['Class'] == 0].copy()\n",
    "fraude = df[df['Class'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantidade de registros normais: ', len(df[df['Class'] == 0]))\n",
    "print('Quantidade de registros fraldados: ', len(df[df['Class'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar a distribuição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex = True)\n",
    "plt.suptitle('Dispersão dos dados entre Valor da transação e Data da operação')\n",
    "\n",
    "ax1.set_title('Normal')\n",
    "sns.scatterplot(data=normal, x='Data', y='Amount', ax=ax1)\n",
    "\n",
    "ax2.set_title('Fraude')\n",
    "sns.scatterplot(data=fraude, x='Data', y='Amount', ax=ax2, color='red')\n",
    "\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Valor da transação')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex = True)\n",
    "f.suptitle('Montante por transação por classe')\n",
    "\n",
    "bins = 50\n",
    "\n",
    "ax1.hist(fraude['Amount'], bins = bins)\n",
    "ax1.set_title('Fraude')\n",
    "\n",
    "ax2.hist(normal['Amount'], bins = bins)\n",
    "ax2.set_title('Normal')\n",
    "\n",
    "plt.xlabel('Total ($)')\n",
    "plt.ylabel('Número de Transações')\n",
    "plt.xlim((0, 20000))\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns[1:30]\n",
    "\n",
    "plt.suptitle('Distribuição e Boxplot dos dados')\n",
    "fig, axs = plt.subplots(nrows=len(columns), ncols=2, figsize=(16,90))\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    ax0 = axs[i, 0]\n",
    "    ax0.set_title('Histograma [{}]'.format(column))\n",
    "    sns.histplot(data=df, x=column, hue='Class', ax=ax0)\n",
    "    \n",
    "    ax1 = axs[i, 1]\n",
    "    ax1.set_title('Boxplot [{}]'.format(column))\n",
    "    sns.boxplot(data=df, x=column, hue='Class', ax=ax1, orient='h')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Correlação')\n",
    "\n",
    "mask = np.zeros_like(df.corr(), dtype=np.bool8)\n",
    "mask[np.triu_indices_from(mask)]= True\n",
    "\n",
    "\n",
    "sns.heatmap(df.corr(), mask=mask, square=True, linewidths=0.5, cmap='viridis', vmin=-1, vmax=1, annot_kws={'size': 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que não existe uma correlação muito forte entre os dados, apenas uma feature ou outra possui um correlacionamento. Vamos remover os correlacionamentos com valor acima de 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORR = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.drop(columns=['Class', 'Time', 'Data']).corr().abs()\n",
    "\n",
    "sol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool8))\n",
    "                  .unstack()\n",
    "                  .sort_values(ascending=False))\n",
    "col_corr = list(map(lambda x: x[1], sol[sol.values > CORR].keys()))\n",
    "print('Colunas com correlação > {} %'.format(CORR), col_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover a informação de `Time, Class e Data` e as colunas com correlação do dataset pois esses features não serão utilizadas na previsão e vamos precisar padronizar o valor de `Amount` para que não haja diferença de escala com base nos outros valores das demais features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "normal['Amount'] = scaler.transform(normal['Amount'].values.reshape(-1,1))\n",
    "fraude['Amount'] = scaler.transform(fraude['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_normal = normal['Class'].values\n",
    "y_fraude = fraude['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = normal.drop(columns=['Class', 'Time', 'Data']).drop(columns=col_corr)\n",
    "fraude = fraude.drop(columns=['Class', 'Time', 'Data']).drop(columns=col_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de custo benefício\n",
    "\n",
    "Vamos criar uma função para validar aqui o quanto de benefício nosso modelo trará ao identificar as fraudes e o custo que teremos caso essas fraudes passem.\n",
    "\n",
    "### Definição para a validação do custo/benefício\n",
    "\n",
    "!['Fraude com cartão'](./images/fraude.png)\n",
    "\n",
    "https://risk.lexisnexis.com/global/pt/about-us/press-room/press-release/20211020-true-cost-of-fraud-latam\n",
    "\n",
    "Dado que o valor de uma transação seja 1,00 real e que para uma empresa checar se o consumidor realmenente adquiriu um bem ela gaste 10% desse valor e 386% o valor da transação para solucionar a fraude, qual o impacto operacional se um modelo conseguir impedir uma fraude ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_custo_beneficio(tp, fp, tn, fn, valor_transacao = 1.0):\n",
    "    \"\"\"Exibe uma matriz de custo/benefício\"\"\"\n",
    " \n",
    "    receita_operacional = tp * valor_transacao\n",
    "    fraude_identificada = fp * valor_transacao * 3.86\n",
    "    \n",
    "    receita_validada = tn * valor_transacao * .9\n",
    "    fraude_validada = tn * valor_transacao * .1\n",
    "    \n",
    "    receita_fraudada = fn * valor_transacao * 3.86\n",
    "    \n",
    "    print('Total de transações: {}'.format(tp + tn + fp + fn))\n",
    "    print('-'.center(20, '-'))\n",
    "    \n",
    "    print('{} Transações válidas'.format(tp + tn))\n",
    "    print('= Receita total: {:.2f}'.format(receita_operacional + receita_validada))\n",
    "    print('+ {} Transações válidas: {:.2f}'.format(tp, receita_operacional))\n",
    "    print('+ {} Transações checadas: {:.2f}'.format(tn, receita_validada))\n",
    "    print('- Custom com checagem: {:.2f}'.format(fraude_validada))\n",
    "\n",
    "    print('-'.center(20, '-'))\n",
    "    print('{} Fraudes'.format(fp + fn))\n",
    "    print('- Custo {:.2f}'.format(receita_fraudada))\n",
    "    print('+ Fraude identificada (save): {:.2f}'.format(fraude_identificada))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base line\n",
    "\n",
    "Vamos criar um modelo baseline para o nosso modelo principal. O objetivo desse modelo base line e validar como duas estruturas de aprendizados podem chegar a um valor muito próximo um do outro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar um classificador do tipo Support Vector Machine para fazer a classificação dos dados. Para isso, vamos obter uma amostra do dataset de registros normais com a mesma quantidade de registros fraudados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normal.sample(len(fraude))\n",
    "y = y_normal[X.index - 1]\n",
    "\n",
    "X = pd.concat([X, fraude])\n",
    "y = np.concatenate((y, y_fraude), axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar as massas de treino e teste e criar o classificador SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', random_state=RANDOM_SEED)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar como foi o treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score: {}' .format(svc.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora avaliar o teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos validar se o modelo conseguiria identificar os registros de fraude na base desbalanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([normal, fraude])\n",
    "y = np.concatenate((y_normal, y_fraude), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = np.random.permutation(len(X))\n",
    "\n",
    "X = X.iloc[indexs]\n",
    "y = y[indexs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora validar o quanto o nosso modelo performance em questão de custo/beneficio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_svc = pd.DataFrame(confusion_matrix(y, y_pred), columns=LABELS)\n",
    "cf_svc.index = LABELS\n",
    "cf_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcular_custo_beneficio(cf_svc.loc['Normal']['Normal'], cf_svc.loc['Fraude']['Fraude'],\n",
    "                           cf_svc.loc['Normal']['Fraude'], cf_svc.loc['Fraude']['Normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura do modelo\n",
    "\n",
    "Vamos utilizar um modelo baseado em Autoencoders, com aprendizado não-supervisioinado, para aprender as caracteristicas de transações normais e vamos utilizar do processo de reconstrução para identificar os registros com anomalias, uma vez que os registros com `Fraude` terão um erro de reconstrução maior devido ao modelo não \"conhecer\" essas caracteristicas que o definem como fraudulento.\n",
    "\n",
    "!['Autoencoder'](./images/autoencoders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dividir os dados em treino e teste para criar nosso modelo. Como vamos criar um modelo baseado em `autoencoders` e aprender as caracteristicas das transações válidas, vamos filtrar primeiramente apenas os registros com a classe `Normal` e dividi-los em sub-amostragens para treino e teste. Os registros com classe `Fraude` serão utilizadas apenas no processo de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(normal, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Treino: ', train.shape)\n",
    "print('Test: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = len(train.columns)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do modelo\n",
    "\n",
    "Vamos definir nosso modelo inicialmente criando a camada de encoder e posterior a camanda de decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (features,)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Sequential([\n",
    "    Dense(24, input_shape=input_shape, kernel_initializer='random_normal'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(),\n",
    "    Dense(18, kernel_initializer='random_normal'),\n",
    "    LeakyReLU(),\n",
    "    Dense(12, kernel_initializer='random_normal'),\n",
    "    LeakyReLU(),\n",
    "    Dense(6, kernel_initializer='random_normal'),\n",
    "    LeakyReLU(),\n",
    "], name='encoding')\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(12, kernel_initializer='random_normal'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(),\n",
    "    Dense(18, kernel_initializer='random_normal'),\n",
    "    LeakyReLU(),\n",
    "    Dense(24, kernel_initializer='random_normal'),\n",
    "    LeakyReLU(),\n",
    "    Dense(train.shape[1], activation='linear', kernel_initializer='random_normal')\n",
    "], name='decoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([encoder, decoder], name='autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(0.01), loss = 'mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary(), decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, min_lr=0.001, factor=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint('./model/autoencoders.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(train, train, batch_size=256, validation_data=(test, test), epochs=500, callbacks=[cp, rp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Analise do modelo treinado')\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title('Erro do Modelo')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Erro')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Treino', 'Teste'], loc = 'best')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Acurácia do Modelo')\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Acurácia')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Treino', 'Teste'], loc = 'best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./model/autoencoders.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executando o modelo para prever as classes de testes\n",
    "\n",
    "Vamos inserir agora nos dados de testes os registros de fraude e validar como o modelo conseguirá classificar os registros de fraude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test, fraude])\n",
    "test = test.iloc[np.random.permutation(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos identificar agora o erro da reconstrução gerada pelo modelo. O erro de reconstrução vai ser utilizado para prever a probabilidade de uma amostra ser uma instância fraudada. \n",
    "\n",
    "O fato de termos utilizado apenas registros `normais` para o treinamento do modelo do autoencoder é que durante o processo de inferência os registros com fraude perde as caracteristicas da fraude e o decodificador as reconstroi como sendo um registro normal, resultando em um grande erro de reconstrução.\n",
    "\n",
    "Depois de calcular todos os erros no dataset de teste podemos gerar uma probabilidade, entre 0 e 1, indicando o percentual de anômalia que essa instancia possui. Com base nisso, podemos definir um threshold para limitar quais registros são anômalos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de calculo de erro para reconstrução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos buscar as labels para os registros de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.iloc[test.index]['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar o erro quadrático médio para achar o erro de reconstrução do modelo.\n",
    "\n",
    "$$\\textstyle L(x,x') = ||\\, x - x'||^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = np.mean(np.power(test-test_pred, 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = np.array(labels_pred).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos normalizar os erros para eles ficarem em uma mesma escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro_scaler = MinMaxScaler()\n",
    "previsao_fraude = erro_scaler.fit_transform(labels_pred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao_fraude[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [i for i, label in enumerate(labels) if label == 1]\n",
    "\n",
    "print(labels[true_labels[0:5]])\n",
    "print(previsao_fraude[true_labels[0:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar agora se o modelo foi capaz de identificar as anomalias nas transações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Transações com % de probabilidade de ser fraude')\n",
    "plt.plot(labels, c='blue', label='Transação')\n",
    "plt.plot(previsao_fraude, c='red', label='$\\hat{P}$ fraude')\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('Transações')\n",
    "plt.ylabel('Score de fraudes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do modelo\n",
    "\n",
    "Vamos avaliar agora se o nosso modelo teve uma boa taxa de acerto nos dados de testes. Vamos utilizar a curva ROC-AUC para medir a eficácia de nosso modelo em distingir as duas classes. \n",
    "\n",
    "Valores perto do canto superior esquerdo, perto de 1, indicam que o classificar é bom em distinguir as classes e valores abaixo da área média, perto de 0.5, indicam que o modelo não conseguiu distinguir entre as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(labels, previsao_fraude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_auc = roc_auc_score(labels, previsao_fraude)\n",
    "print('Score AUC: ', score_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.title('ROC')\n",
    "plt.plot([0, 1], [0, 1], color = 'black', linestyle = '--')\n",
    "plt.plot(fpr, tpr, label = 'AUC = {}'.format(score_auc))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso modelo conseguiu classificar bem os eventos com transações com as duas labels. Porém como temos dados desbalanceados o ROC pode não expressar corretamente o quao bom ou ruim esta nosso modelo. Vamos utilizar para isso outras métricas de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precisão vs Recal\n",
    "\n",
    "!['Precisao vs Recall'](./images/precision_recall.png)\n",
    "\n",
    "Precisão e Recall são métricas para avaliar o quanto um modelo esta conseguindo identificar as classes corretas durante um processo de classificação. Porém a precisão e o recall tem objetivos distintos na identificação do quão bem o modelo esta classificando.\n",
    "\n",
    "Precisão e recall são definidos da seguinte forma:\n",
    "\n",
    "$$\\text{Precision} = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false positives}}$$\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false negatives}}$$\n",
    "\n",
    "* A precisão mede a relevância dos resultados obtidos. \n",
    "\n",
    "* Recall, por outro lado, mede quantos resultados relevantes são retornados.\n",
    "\n",
    "Ambos os valores podem ter valores entre 0 e 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos calcular agora os valores e plotar em um gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, th = precision_recall_curve(labels, previsao_fraude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Recall vs Precisão')\n",
    "plt.plot(recall, precision, 'b', label = 'Curva Precisão-Recall')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precisão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(th, precision[1:], 'b', label = 'Curva Threshold-Precisão')\n",
    "plt.title('Precisão Para Diferentes Valores de threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precisão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(th, recall[1:], 'b', label = 'Curva Threshold-Recall')\n",
    "plt.title('Recall Para Diferentes Valores de threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificando fraudes\n",
    "\n",
    "Precisamos agora definir um limite de threshold para o nosso modelo. Valores acima desse limite indicaram que os registros possuem fraude na transação, então precisamos achar um valor que consiga identificar o maior número possível de fraudes.\n",
    "\n",
    "Vamos utilizar como base a métrica de F1-Score, que é uma média harmônica de precisão e recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limites_fraude = [(previsao_fraude > i).astype(np.int32) for i in threshold]\n",
    "f1_scores = [f1_score(labels, i) for i in limites_fraude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "plt.title('F-1 Score vs Thresholds')\n",
    "plt.plot(threshold, f1_scores)\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('F-1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos obter o melhor threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(f1_scores))\n",
    "print(np.max(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor_threshold = threshold[f1_scores.index(np.max(f1_scores))]\n",
    "print('Melhor Threshold = {}'.format(melhor_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora classificar nossos registros com base nesse threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicador_fraude = (previsao_fraude > (melhor_threshold)).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicador_fraude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar agora como ficou as classificações dos registros com base no threshold selecionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model = pd.DataFrame(confusion_matrix(labels, indicador_fraude), columns=LABELS)\n",
    "cf_model.index = LABELS\n",
    "print(cf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicador_fraude_final = ['normal' if i == 0 else 'fraude' for i in indicador_fraude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Transações com % de probabilidade de ser fraude')\n",
    "plt.plot(labels, c='blue', label='Transação')\n",
    "plt.plot(previsao_fraude, c='red', label='$\\hat{P}$ fraude')\n",
    "\n",
    "plt.axhline(y = melhor_threshold, linestyle = '--', label = 'threshold', color='black')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xlabel('Transações')\n",
    "plt.ylabel('Score de fraudes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(labels, indicador_fraude)\n",
    "recall = recall_score(labels, indicador_fraude)\n",
    "f1_sc = f1_score(labels, indicador_fraude)\n",
    "accuracy_sc = accuracy_score(labels, indicador_fraude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Métricas de Avaliação do Modelo:\n",
    "         Precision = {}\n",
    "         Recall = {}\n",
    "         Score F1 = {}\n",
    "         Acurácia = {}\"\"\"\n",
    "      .format(precision, recall, f1_sc, accuracy_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels, indicador_fraude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcular_custo_beneficio(cf_model.loc['Normal']['Normal'], cf_model.loc['Fraude']['Fraude'],\n",
    "                           cf_model.loc['Normal']['Fraude'], cf_model.loc['Fraude']['Normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fb0c83d26dfee852088ccf90efed194bfc1e2010a06069a41d5c2610fba13de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tcc': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
